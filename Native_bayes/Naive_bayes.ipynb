{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Naive Bayes classification using Sci-kit Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1] \n",
      " temp:  [1 1 1 2 0 0 0 2 0 2 2 2 1 2] \n",
      " play:  [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "------------- Combination of features --------------\n",
      "[(2, 1), (2, 1), (0, 1), (1, 2), (1, 0), (1, 0), (0, 0), (2, 2), (2, 0), (1, 2), (2, 2), (0, 2), (0, 1), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "#Define the dataset\n",
    "#Assigning features and Label variables\n",
    "\n",
    "Weather = ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "Temperature = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild' ]\n",
    "Play = ['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
    "\n",
    "#using LabelEncoder from sklearn to convert strings to numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#creating the model\n",
    "le = LabelEncoder()\n",
    "\n",
    "#convert string to numbers\n",
    "weather_encoded = le.fit_transform(Weather)\n",
    "temp_encoded = le.fit_transform(Temperature)\n",
    "play_encoded = le.fit_transform(Play)\n",
    "print(weather_encoded, '\\n' ,'temp: ' ,temp_encoded, '\\n play: ', play_encoded )\n",
    "\n",
    "print('------------- Combination of features --------------')\n",
    "#combinng both weather and temperature into a single list of tuples for easier prediction\n",
    "both_features = [tup for tup in zip(weather_encoded, temp_encoded)]\n",
    "print(both_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating model using NB classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value:  [1]\n"
     ]
    }
   ],
   "source": [
    "#import gaussian naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#creating a gaussian\n",
    "model = GaussianNB()\n",
    "\n",
    "#fit the dataset on classifier\n",
    "model.fit(both_features,play_encoded)\n",
    "\n",
    "#perform prediction with a new dataset which has [3,2] which is overcast and mild\n",
    "y_pred = model.predict([[0,2]])\n",
    "\n",
    "print(\"Predicted Value: \", y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NAIVE BAYES WITH MULTIPLE LABELS\n",
    "\n",
    "EXPLORING DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "\n",
      " Labels:  ['class_0' 'class_1' 'class_2']\n",
      "(178, 13)\n",
      "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0     14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1     13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2     13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3     14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4     13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "5     14.20        1.76  2.45               15.2      112.0           3.27   \n",
      "6     14.39        1.87  2.45               14.6       96.0           2.50   \n",
      "7     14.06        2.15  2.61               17.6      121.0           2.60   \n",
      "8     14.83        1.64  2.17               14.0       97.0           2.80   \n",
      "9     13.86        1.35  2.27               16.0       98.0           2.98   \n",
      "10    14.10        2.16  2.30               18.0      105.0           2.95   \n",
      "11    14.12        1.48  2.32               16.8       95.0           2.20   \n",
      "12    13.75        1.73  2.41               16.0       89.0           2.60   \n",
      "13    14.75        1.73  2.39               11.4       91.0           3.10   \n",
      "14    14.38        1.87  2.38               12.0      102.0           3.30   \n",
      "15    13.63        1.81  2.70               17.2      112.0           2.85   \n",
      "16    14.30        1.92  2.72               20.0      120.0           2.80   \n",
      "17    13.83        1.57  2.62               20.0      115.0           2.95   \n",
      "18    14.19        1.59  2.48               16.5      108.0           3.30   \n",
      "19    13.64        3.10  2.56               15.2      116.0           2.70   \n",
      "20    14.06        1.63  2.28               16.0      126.0           3.00   \n",
      "21    12.93        3.80  2.65               18.6      102.0           2.41   \n",
      "22    13.71        1.86  2.36               16.6      101.0           2.61   \n",
      "23    12.85        1.60  2.52               17.8       95.0           2.48   \n",
      "24    13.50        1.81  2.61               20.0       96.0           2.53   \n",
      "25    13.05        2.05  3.22               25.0      124.0           2.63   \n",
      "26    13.39        1.77  2.62               16.1       93.0           2.85   \n",
      "27    13.30        1.72  2.14               17.0       94.0           2.40   \n",
      "28    13.87        1.90  2.80               19.4      107.0           2.95   \n",
      "29    14.02        1.68  2.21               16.0       96.0           2.65   \n",
      "\n",
      "    flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0         3.06                  0.28             2.29             5.64  1.04   \n",
      "1         2.76                  0.26             1.28             4.38  1.05   \n",
      "2         3.24                  0.30             2.81             5.68  1.03   \n",
      "3         3.49                  0.24             2.18             7.80  0.86   \n",
      "4         2.69                  0.39             1.82             4.32  1.04   \n",
      "5         3.39                  0.34             1.97             6.75  1.05   \n",
      "6         2.52                  0.30             1.98             5.25  1.02   \n",
      "7         2.51                  0.31             1.25             5.05  1.06   \n",
      "8         2.98                  0.29             1.98             5.20  1.08   \n",
      "9         3.15                  0.22             1.85             7.22  1.01   \n",
      "10        3.32                  0.22             2.38             5.75  1.25   \n",
      "11        2.43                  0.26             1.57             5.00  1.17   \n",
      "12        2.76                  0.29             1.81             5.60  1.15   \n",
      "13        3.69                  0.43             2.81             5.40  1.25   \n",
      "14        3.64                  0.29             2.96             7.50  1.20   \n",
      "15        2.91                  0.30             1.46             7.30  1.28   \n",
      "16        3.14                  0.33             1.97             6.20  1.07   \n",
      "17        3.40                  0.40             1.72             6.60  1.13   \n",
      "18        3.93                  0.32             1.86             8.70  1.23   \n",
      "19        3.03                  0.17             1.66             5.10  0.96   \n",
      "20        3.17                  0.24             2.10             5.65  1.09   \n",
      "21        2.41                  0.25             1.98             4.50  1.03   \n",
      "22        2.88                  0.27             1.69             3.80  1.11   \n",
      "23        2.37                  0.26             1.46             3.93  1.09   \n",
      "24        2.61                  0.28             1.66             3.52  1.12   \n",
      "25        2.68                  0.47             1.92             3.58  1.13   \n",
      "26        2.94                  0.34             1.45             4.80  0.92   \n",
      "27        2.19                  0.27             1.35             3.95  1.02   \n",
      "28        2.97                  0.37             1.76             4.50  1.25   \n",
      "29        2.33                  0.26             1.98             4.70  1.04   \n",
      "\n",
      "    od280/od315_of_diluted_wines  proline  target  \n",
      "0                           3.92   1065.0       0  \n",
      "1                           3.40   1050.0       0  \n",
      "2                           3.17   1185.0       0  \n",
      "3                           3.45   1480.0       0  \n",
      "4                           2.93    735.0       0  \n",
      "5                           2.85   1450.0       0  \n",
      "6                           3.58   1290.0       0  \n",
      "7                           3.58   1295.0       0  \n",
      "8                           2.85   1045.0       0  \n",
      "9                           3.55   1045.0       0  \n",
      "10                          3.17   1510.0       0  \n",
      "11                          2.82   1280.0       0  \n",
      "12                          2.90   1320.0       0  \n",
      "13                          2.73   1150.0       0  \n",
      "14                          3.00   1547.0       0  \n",
      "15                          2.88   1310.0       0  \n",
      "16                          2.65   1280.0       0  \n",
      "17                          2.57   1130.0       0  \n",
      "18                          2.82   1680.0       0  \n",
      "19                          3.36    845.0       0  \n",
      "20                          3.71    780.0       0  \n",
      "21                          3.52    770.0       0  \n",
      "22                          4.00   1035.0       0  \n",
      "23                          3.63   1015.0       0  \n",
      "24                          3.82    845.0       0  \n",
      "25                          3.20    830.0       0  \n",
      "26                          3.22   1195.0       0  \n",
      "27                          2.77   1285.0       0  \n",
      "28                          3.40    915.0       0  \n",
      "29                          3.59   1035.0       0  \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#import scik-it learn dataset library\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#load dataset\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "#print the names of the 13 features - features names  is the names of dataset columns\n",
    "print('Features: ', wine.feature_names)\n",
    "\n",
    "#print the label type of wine (class_0, class_1, class_2) - target_names - names of target\n",
    "print('\\n Labels: ', wine.target_names)\n",
    "\n",
    "#print the data shape\n",
    "print(wine.data.shape)\n",
    "\n",
    "#print the wine in a pandas dataframe to have a better view, you need to import the wine data from scikit learn library to a pandas dataframe\n",
    "import pandas as pd\n",
    "features = pd.DataFrame(data=wine['data'],columns=wine['feature_names'])\n",
    "features['target']=wine['target']\n",
    "print(features.head(30))\n",
    "\n",
    "#print the wine labels\n",
    "print(wine.target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data,\n",
    "                                                    wine.target,\n",
    "                                                    test_size=0.3,   # 70% training and 30% test\n",
    "                                                    random_state=109)\n",
    "\n",
    "#print (\"X_train: \", X_train)\n",
    "#print (\"y_train: \", y_train)\n",
    "#print(\"X_test: \", X_test)\n",
    "#print (\"y_test: \", y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EVALUATE MODEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9074074074074074\n",
      "Accuracy: 0.8533405757740359\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"R2 score:\",metrics.r2_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
